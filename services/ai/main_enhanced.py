from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uuid
import asyncio
import json
import httpx
from typing import Dict, Any, Optional
import os
from datetime import datetime

app = FastAPI(title="SmartHire AI Service Enhanced", version="0.2.0")

# Armazenamento em mem√≥ria dos runs (em produ√ß√£o, usar Redis/DB)
runs: Dict[str, Dict[str, Any]] = {}

class TranscribeRequest(BaseModel):
    audio_path: str
    language: str | None = None

class StagePayload(BaseModel):
    id: str | None = None
    name: str | None = None
    threshold: float | None = None
    stage_weight: float | None = None
    job_description: str | None = None

class RequirementPayload(BaseModel):
    label: str | None = None
    description: str | None = None
    weight: float | None = None

class EvaluateRequest(BaseModel):
    stage_id: str
    application_id: str
    resume_path: str | None = None
    audio_path: str | None = None
    transcript_path: str | None = None
    user_id: str | None = None
    stage: StagePayload | None = None
    requirements: list[RequirementPayload] | None = None
    prompt_template: str | None = None

class RunStatus(BaseModel):
    id: str
    type: str
    status: str
    progress: int | None = None
    error: str | None = None
    result: Dict[str, Any] | None = None

class EvaluationResult(BaseModel):
    score: float
    analysis: str
    matched_requirements: list[str]
    missing_requirements: list[str]
    strengths: list[str]
    weaknesses: list[str]
    recommendations: list[str]

class AIConfig(BaseModel):
    openai_api_key: str
    model: str
    temperature: float
    max_tokens: int

# Simula√ß√£o de processamento de √°udio (substituir por Whisper API real)
async def process_audio(audio_path: str) -> str:
    """Simula transcri√ß√£o de √°udio para texto"""
    await asyncio.sleep(2)  # Simula processamento
    return f"Transcri√ß√£o do √°udio {audio_path}: Candidato demonstrou experi√™ncia em vendas e comunica√ß√£o clara."

# Simula√ß√£o de extra√ß√£o de texto de PDF (substituir por PyPDF2 ou similar)
async def extract_pdf_text(pdf_path: str) -> str:
    """Simula extra√ß√£o de texto de PDF"""
    await asyncio.sleep(1)  # Simula processamento
    return f"Curr√≠culo {pdf_path}: Jo√£o Silva, 5 anos de experi√™ncia em vendas, graduado em Administra√ß√£o, fluente em ingl√™s."

# Simula√ß√£o de an√°lise de transcri√ß√£o
async def analyze_transcript(transcript_path: str) -> str:
    """Simula leitura de transcri√ß√£o JSON"""
    await asyncio.sleep(1)
    return f"Transcri√ß√£o {transcript_path}: Candidato mostrou conhecimento t√©cnico e habilidades interpessoais."

# An√°lise real com OpenAI
async def analyze_candidate_with_openai(
    text_content: str, 
    stage_description: str, 
    requirements: list[dict],
    config: AIConfig,
    prompt_template: str | None = None
) -> EvaluationResult:
    """
    An√°lise real do candidato usando OpenAI
    """
    try:
        async with httpx.AsyncClient() as client:
            # Preparar prompt para an√°lise
            requirements_text = "\n".join([
                f"- {req.get('label', '')}: {req.get('description', '')} (peso: {req.get('weight', 1.0)})"
                for req in requirements
            ])
            
            base_prompt = prompt_template or """
Analise o candidato para a vaga baseado nas informa√ß√µes fornecidas.

DESCRI√á√ÉO DA ETAPA:
{{STAGE_DESCRIPTION}}

REQUISITOS DA ETAPA:
{{REQUIREMENTS_LIST}}

INFORMA√á√ïES DO CANDIDATO:
{{CANDIDATE_INFO}}

Forne√ßa uma an√°lise detalhada em JSON v√°lido com as chaves: score (0-10), analysis (texto), matched_requirements (lista), missing_requirements (lista), strengths (lista), weaknesses (lista), recommendations (lista).
"""

            prompt = (
                base_prompt
                .replace("{{STAGE_DESCRIPTION}}", stage_description)
                .replace("{{REQUIREMENTS_LIST}}", requirements_text)
                .replace("{{CANDIDATE_INFO}}", text_content)
            )

            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {config.openai_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": config.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "Voc√™ √© um especialista em RH que analisa candidatos de forma objetiva e justa. Sempre responda em formato JSON v√°lido."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": config.temperature,
                    "max_tokens": config.max_tokens
                },
                timeout=30.0
            )

            if response.status_code != 200:
                raise Exception(f"Erro na API OpenAI: {response.status_code} - {response.text}")

            data = response.json()
            content = data["choices"][0]["message"]["content"]
            
            # Extrair JSON da resposta
            try:
                # Tentar encontrar JSON na resposta
                start = content.find('{')
                end = content.rfind('}') + 1
                if start != -1 and end != 0:
                    json_str = content[start:end]
                    result = json.loads(json_str)
                else:
                    raise ValueError("JSON n√£o encontrado na resposta")
            except (json.JSONDecodeError, ValueError) as e:
                # Fallback para an√°lise simulada se JSON inv√°lido
                return await analyze_candidate_simulated(text_content, stage_description, requirements)

            return EvaluationResult(
                score=float(result.get("score", 5.0)),
                analysis=result.get("analysis", "An√°lise n√£o dispon√≠vel"),
                matched_requirements=result.get("matched_requirements", []),
                missing_requirements=result.get("missing_requirements", []),
                strengths=result.get("strengths", []),
                weaknesses=result.get("weaknesses", []),
                recommendations=result.get("recommendations", [])
            )

    except Exception as e:
        print(f"Erro na an√°lise com OpenAI: {e}")
        # Fallback para an√°lise simulada
        return await analyze_candidate_simulated(text_content, stage_description, requirements)

# An√°lise simulada (fallback)
async def analyze_candidate_simulated(
    text_content: str,
    stage_description: str,
    requirements: list[dict]
) -> EvaluationResult:
    """
    An√°lise simulada do candidato (fallback)
    """
    await asyncio.sleep(2)  # Simula processamento
    
    text_lower = text_content.lower()
    stage_lower = stage_description.lower()
    
    # Pontua√ß√£o base (0-10)
    base_score = 5.0
    
    # An√°lise de correspond√™ncia com descri√ß√£o da etapa
    stage_keywords = ["vendas", "comercial", "atendimento", "cliente", "negocia√ß√£o"]
    stage_matches = sum(1 for keyword in stage_keywords if keyword in text_lower)
    stage_bonus = min(stage_matches * 0.5, 2.0)
    
    # An√°lise de requisitos
    matched_reqs = []
    missing_reqs = []
    strengths = []
    weaknesses = []
    req_bonus = 0.0
    
    for req in requirements:
        req_text = req.get("label", "").lower()
        req_desc = req.get("description", "").lower()
        req_weight = req.get("weight", 1.0)
        
        if req_text in text_lower or req_desc in text_lower:
            matched_reqs.append(req.get("label", ""))
            strengths.append(f"Atende requisito: {req.get('label', '')}")
            req_bonus += 0.5 * req_weight
        else:
            missing_reqs.append(req.get("label", ""))
            weaknesses.append(f"N√£o atende: {req.get('label', '')}")
    
    # C√°lculo da pontua√ß√£o final
    final_score = min(base_score + stage_bonus + req_bonus, 10.0)
    
    # Gera an√°lise textual
    analysis = f"""
    An√°lise do candidato para a etapa:
    
    ‚úÖ Pontos fortes:
    - {len(matched_reqs)} requisitos atendidos
    - Correspond√™ncia com descri√ß√£o da etapa: {stage_matches}/5 palavras-chave
    
    ‚ö†Ô∏è Pontos de melhoria:
    - {len(missing_reqs)} requisitos n√£o identificados
    
    üìä Pontua√ß√£o: {final_score:.1f}/10
    """
    
    return EvaluationResult(
        score=round(final_score, 1),
        analysis=analysis.strip(),
        matched_requirements=matched_reqs,
        missing_requirements=missing_reqs,
        strengths=strengths,
        weaknesses=weaknesses,
        recommendations=["Considerar para pr√≥xima etapa", "Avaliar em entrevista"]
    )

# Buscar configura√ß√µes do usu√°rio (simulado - em produ√ß√£o, buscar do DB)
async def get_user_ai_config(user_id: str) -> AIConfig:
    """
    Busca configura√ß√µes da IA do usu√°rio.
    Se n√£o houver configura√ß√£o persistida, utiliza vari√°veis de ambiente como fallback.
    """
    # TODO: Integrar com Supabase ou servi√ßo BFF para buscar settings reais por usu√°rio
    env_api_key = os.getenv("OPENAI_API_KEY", "")
    env_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    env_temperature = float(os.getenv("OPENAI_TEMPERATURE", "0.3"))
    env_max_tokens = int(os.getenv("OPENAI_MAX_TOKENS", "2000"))

    return AIConfig(
        openai_api_key=env_api_key,
        model=env_model,
        temperature=env_temperature,
        max_tokens=env_max_tokens,
    )

@app.post("/v1/transcribe", response_model=RunStatus)
async def transcribe(request: TranscribeRequest):
    run_id = str(uuid.uuid4())
    runs[run_id] = {
        "id": run_id,
        "type": "transcribe",
        "status": "running",
        "progress": 0,
        "result": None,
        "created_at": datetime.now().isoformat()
    }
    
    asyncio.create_task(process_transcription(run_id, request.audio_path))
    
    return RunStatus(id=run_id, type="transcribe", status="running", progress=0)

async def process_transcription(run_id: str, audio_path: str):
    try:
        runs[run_id]["progress"] = 50
        transcript = await process_audio(audio_path)
        runs[run_id]["status"] = "succeeded"
        runs[run_id]["progress"] = 100
        runs[run_id]["result"] = {"transcript": transcript}
        runs[run_id]["finished_at"] = datetime.now().isoformat()
    except Exception as e:
        runs[run_id]["status"] = "failed"
        runs[run_id]["error"] = str(e)
        runs[run_id]["finished_at"] = datetime.now().isoformat()

@app.post("/v1/evaluate", response_model=RunStatus)
async def evaluate(request: EvaluateRequest):
    run_id = str(uuid.uuid4())
    runs[run_id] = {
        "id": run_id,
        "type": "evaluate",
        "status": "running",
        "progress": 0,
        "result": None,
        "created_at": datetime.now().isoformat()
    }
    
    asyncio.create_task(process_evaluation(run_id, request))
    
    return RunStatus(id=run_id, type="evaluate", status="running", progress=0)

async def process_evaluation(run_id: str, request: EvaluateRequest):
    try:
        runs[run_id]["progress"] = 20
        
        # Coleta conte√∫do de texto
        text_content = ""
        
        if request.resume_path:
            runs[run_id]["progress"] = 40
            text_content += await extract_pdf_text(request.resume_path) + "\n\n"
        
        if request.audio_path:
            runs[run_id]["progress"] = 60
            text_content += await process_audio(request.audio_path) + "\n\n"
        
        if request.transcript_path:
            runs[run_id]["progress"] = 80
            text_content += await analyze_transcript(request.transcript_path) + "\n\n"
        
        # Buscar configura√ß√µes da IA do usu√°rio
        config = await get_user_ai_config(request.user_id or "default")

        # Define descri√ß√£o da etapa e requisitos com base no payload fornecido
        stage_description = request.stage.name or "Etapa do processo seletivo"
        if request.stage.job_description:
            stage_description += f"\nDescri√ß√£o da vaga: {request.stage.job_description}"
        requirements_payload = [
            {
                "label": req.label or "",
                "description": req.description or "",
                "weight": req.weight or 1.0,
            }
            for req in (request.requirements or [])
        ]

        # An√°lise da IA
        runs[run_id]["progress"] = 90
        evaluation = await analyze_candidate_with_openai(
            text_content,
            stage_description,
            requirements_payload,
            config,
            prompt_template=request.prompt_template,
        )
        
        runs[run_id]["status"] = "succeeded"
        runs[run_id]["progress"] = 100
        runs[run_id]["result"] = {
            "score": evaluation.score,
            "analysis": evaluation.analysis,
            "matched_requirements": evaluation.matched_requirements,
            "missing_requirements": evaluation.missing_requirements,
            "strengths": evaluation.strengths,
            "weaknesses": evaluation.weaknesses,
            "recommendations": evaluation.recommendations,
            "stage_id": request.stage_id,
            "application_id": request.application_id,
            "prompt_template": request.prompt_template,
            "stage": request.stage.dict() if request.stage else None,
            "requirements": [req.dict() for req in (request.requirements or [])],
        }
        runs[run_id]["finished_at"] = datetime.now().isoformat()
        
    except Exception as e:
        runs[run_id]["status"] = "failed"
        runs[run_id]["error"] = str(e)
        runs[run_id]["finished_at"] = datetime.now().isoformat()

@app.get("/v1/runs/{run_id}", response_model=RunStatus)
async def get_run(run_id: str):
    if run_id not in runs:
        raise HTTPException(status_code=404, detail="Run not found")
    
    run_data = runs[run_id]
    return RunStatus(
        id=run_data["id"],
        type=run_data["type"],
        status=run_data["status"],
        progress=run_data["progress"],
        error=run_data.get("error"),
        result=run_data.get("result")
    )

@app.get("/health")
async def health():
    return {
        "status": "healthy", 
        "runs_active": len([r for r in runs.values() if r["status"] == "running"]),
        "version": "0.2.0"
    }

# Endpoint para testar configura√ß√£o da IA
@app.post("/v1/test-config")
async def test_config(config: AIConfig):
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {config.openai_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": config.model,
                    "messages": [
                        {
                            "role": "user",
                            "content": "Teste de conex√£o. Responda apenas 'OK' se recebeu esta mensagem."
                        }
                    ],
                    "max_tokens": 10,
                    "temperature": 0
                },
                timeout=10.0
            )
            
            if response.status_code == 200:
                return {"success": True, "message": "Configura√ß√£o v√°lida"}
            else:
                return {"success": False, "message": f"Erro: {response.status_code}"}
                
    except Exception as e:
        return {"success": False, "message": f"Erro: {str(e)}"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
