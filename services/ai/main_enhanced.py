from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uuid
import asyncio
import json
import io
import base64
import httpx
from typing import Dict, Any, Optional, Tuple
import os
from datetime import datetime
from pathlib import Path
import tempfile
from urllib.parse import urlparse
import base64
import os
from dotenv import load_dotenv, dotenv_values
# Carregamento seguro de vari√°veis de ambiente
def load_environment_variables():
    """
    Carrega vari√°veis de ambiente de forma segura, tratando problemas de encoding
    """
    try:
        # Verificar se arquivo .env existe
        env_file = Path(".env")
        if env_file.exists():
            print(f"[IA] Arquivo .env encontrado: {env_file.absolute()}")
            try:
                # Tentar diferentes encodings (inclui UTF-16/UTF-32)
                encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'utf-16', 'utf-16-le', 'utf-16-be', 'utf-32', 'utf-32-le', 'utf-32-be']
                loaded = False

                for encoding in encodings:
                    try:
                        result = load_dotenv(encoding=encoding)
                        if result:
                            print(f"[IA] ‚úÖ .env carregado com sucesso usando encoding: {encoding}")
                            loaded = True
                            break
                    except UnicodeDecodeError:
                        print(f"[IA] ‚ùå Falha com encoding {encoding}, tentando pr√≥ximo...")
                        continue
                    except Exception as e:
                        print(f"[IA] ‚ùå Erro com encoding {encoding}: {e}")
                        break

                if not loaded:
                    print(f"[IA] ‚ùå N√£o foi poss√≠vel carregar .env com nenhum encoding")
                    print(f"[IA] üîÑ Tentando carregar manualmente...")

                    # Tentar carregar manualmente com diferentes encodings e via dotenv_values
                    manual_loaded = False

                    # 1) dotenv_values
                    try:
                        values = dotenv_values(dotenv_path=str(env_file))
                        if values:
                            for k, v in values.items():
                                if k and v is not None and os.getenv(k) is None:
                                    os.environ[k] = str(v)
                            manual_loaded = True
                            print(f"[IA] ‚úÖ .env carregado via dotenv_values")
                    except Exception as e:
                        print(f"[IA] ‚ùå dotenv_values falhou: {e}")

                    # 2) Parsing manual
                    if not manual_loaded:
                        for encoding in encodings:
                            try:
                                with open('.env', 'r', encoding=encoding) as f:
                                    content = f.read()
                                    # Remover BOM se houver
                                    if content.startswith('\ufeff'):
                                        content = content.lstrip('\ufeff')
                                    for raw_line in content.split('\n'):
                                        line = raw_line.strip()
                                        if not line or line.startswith('#'):
                                            continue
                                        if '=' not in line:
                                            continue
                                        key, value = line.split('=', 1)
                                        key = key.strip()
                                        value = value.strip().strip('"\'')
                                        if key and os.getenv(key) is None:
                                            os.environ[key] = value
                                    manual_loaded = True
                                    print(f"[IA] ‚úÖ .env carregado manualmente com encoding: {encoding}")
                                    break
                            except UnicodeDecodeError:
                                print(f"[IA] ‚ùå Falha no carregamento manual com {encoding}: UnicodeDecodeError")
                                continue
                            except Exception as e:
                                print(f"[IA] ‚ùå Falha no carregamento manual com {encoding}: {e}")
                                continue

                    if not manual_loaded:
                        print(f"[IA] ‚ùå N√£o foi poss√≠vel carregar .env manualmente")
                        print(f"[IA] ‚ö†Ô∏è Continuando sem carregar .env")
                        return False

                return True

            except ImportError:
                print(f"[IA] ‚ùå python-dotenv n√£o instalado")
                print(f"[IA] ‚ö†Ô∏è Continuando sem carregar .env")
                return False
            except Exception as e:
                print(f"[IA] ‚ùå Erro ao carregar .env: {e}")
                print(f"[IA] ‚ö†Ô∏è Continuando sem carregar .env")
                return False
        else:
            print(f"[IA] Arquivo .env n√£o encontrado em: {env_file.absolute()}")
            print(f"[IA] ‚ö†Ô∏è Usando apenas vari√°veis de ambiente do sistema")
            return False
    except Exception as e:
        print(f"[IA] ‚ùå Erro cr√≠tico no carregamento de vari√°veis: {e}")
        return False

print("[IA] ========== INICIANDO CARREGAMENTO DE VARI√ÅVEIS ==========")
env_loaded = load_environment_variables()

# Verificar se as vari√°veis foram carregadas
supabase_url = os.getenv("SUPABASE_URL")
service_role = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
storage_url = os.getenv("SUPABASE_STORAGE_URL")

print(f"[IA] ========== STATUS DAS VARI√ÅVEIS ==========")
print(f"[IA] SUPABASE_URL carregada: {bool(supabase_url)}")
print(f"[IA] SUPABASE_SERVICE_ROLE_KEY carregada: {bool(service_role)}")
print(f"[IA] SUPABASE_STORAGE_URL carregada: {bool(storage_url)}")

# Verificar vari√°veis cr√≠ticas
if not supabase_url:
    print(f"[IA] ‚ùå SUPABASE_URL n√£o configurada - verifique seu arquivo .env ou vari√°veis de ambiente")
if not service_role:
    print(f"[IA] ‚ùå SUPABASE_SERVICE_ROLE_KEY n√£o configurada - verifique seu arquivo .env ou vari√°veis de ambiente")

try:
    from PyPDF2 import PdfReader  # type: ignore
except ImportError:
    PdfReader = None

try:
    import docx  # type: ignore
except ImportError:
    docx = None

try:
    import pytesseract  # type: ignore
    from PIL import Image  # type: ignore
except ImportError:
    pytesseract = None
    Image = None

SUPPORTED_RESUME_EXTENSIONS = {".pdf", ".docx", ".doc", ".txt"}
SUPPORTED_IMAGE_EXTENSIONS = {".png", ".jpg", ".jpeg"}

app = FastAPI(title="SmartHire AI Service Enhanced", version="0.2.0")

# Armazenamento em mem√≥ria dos runs (em produ√ß√£o, usar Redis/DB)
runs: Dict[str, Dict[str, Any]] = {}

class TranscribeRequest(BaseModel):
    audio_path: str
    language: str | None = None

class StagePayload(BaseModel):
    id: str | None = None
    name: str | None = None
    threshold: float | None = None
    stage_weight: float | None = None
    description: str | None = None
    job_description: str | None = None

class RequirementPayload(BaseModel):
    label: str | None = None
    description: str | None = None
    weight: float | None = None

class EvaluateRequest(BaseModel):
    stage_id: str
    application_id: str
    resume_path: str | None = None
    resume_bucket: str | None = None
    resume_signed_url: str | None = None
    audio_path: str | None = None
    audio_bucket: str | None = None
    audio_signed_url: str | None = None
    transcript_path: str | None = None
    transcript_bucket: str | None = None
    transcript_signed_url: str | None = None
    user_id: str | None = None
    stage: StagePayload | None = None
    requirements: list[RequirementPayload] | None = None
    prompt_template: str | None = None

class RunStatus(BaseModel):
    id: str
    type: str
    status: str
    progress: int | None = None
    error: str | None = None
    result: Dict[str, Any] | None = None

class EvaluationResult(BaseModel):
    score: float
    analysis: str
    matched_requirements: list[str]
    missing_requirements: list[str]
    strengths: list[str]
    weaknesses: list[str]
    recommendations: list[str]

class AIConfig(BaseModel):
    openai_api_key: str
    model: str
    temperature: float
    max_tokens: int

# Simula√ß√£o de processamento de √°udio (substituir por Whisper API real)
async def process_audio(audio_path: str) -> str:
    """Simula transcri√ß√£o de √°udio para texto"""
    await asyncio.sleep(2)  # Simula processamento
    return f"Transcri√ß√£o do √°udio {audio_path}: Candidato demonstrou experi√™ncia em vendas e comunica√ß√£o clara."

# Utilidades de extra√ß√£o real de texto de curr√≠culos
async def read_file_bytes(path: Path) -> bytes:
    return await asyncio.to_thread(path.read_bytes)


async def extract_text_from_pdf(path: Path) -> str:
    if PdfReader is None:
        raise RuntimeError("Depend√™ncia PyPDF2 n√£o instalada")

    file_bytes = await read_file_bytes(path)

    def _extract() -> str:
        reader = PdfReader(io.BytesIO(file_bytes))
        texts = []
        for page in reader.pages:
            try:
                texts.append(page.extract_text() or "")
            except Exception:
                continue
        return "\n".join(filter(None, texts))

    return await asyncio.to_thread(_extract)


async def extract_text_from_docx(path: Path) -> str:
    if docx is None:
        raise RuntimeError("Depend√™ncia python-docx n√£o instalada")

    def _extract() -> str:
        document = docx.Document(str(path))
        paragraphs = [para.text for para in document.paragraphs if para.text]
        return "\n".join(paragraphs)

    return await asyncio.to_thread(_extract)


async def extract_text_from_plain(path: Path) -> str:
    file_bytes = await read_file_bytes(path)
    return file_bytes.decode("utf-8", errors="ignore")


async def extract_text_with_ocr(path: Path) -> str:
    if pytesseract is None or Image is None:
        raise RuntimeError("Depend√™ncias de OCR n√£o instaladas")

    file_bytes = await read_file_bytes(path)

    def _extract() -> str:
        with Image.open(io.BytesIO(file_bytes)) as img:
            return pytesseract.image_to_string(img)

    return await asyncio.to_thread(_extract)
async def download_file_from_storage(path: str, bucket: str | None = None) -> Path:
    storage_url = os.getenv("SUPABASE_STORAGE_URL")
    service_role = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
    if not storage_url or not service_role:
        raise RuntimeError("SUPABASE_STORAGE_URL ou SUPABASE_SERVICE_ROLE_KEY n√£o configurados")

    actual_bucket = bucket
    file_path = path

    if path.startswith("http"):
        parsed = urlparse(path)
        file_path = parsed.path.lstrip('/')
        if not bucket and '/' in file_path:
            parts = file_path.split('/', 1)
            actual_bucket = parts[0]
            file_path = parts[1]
    else:
        if '/' in path:
            parts = path.split('/', 1)
            if len(parts) == 2:
                actual_bucket = parts[0]
                file_path = parts[1]

    if not actual_bucket:
        raise ValueError("Bucket n√£o informado para download do arquivo")

    download_url = f"{storage_url}/object/{actual_bucket}/{file_path}"

    async with httpx.AsyncClient() as client:
        response = await client.get(download_url, timeout=60.0, headers={
            "Authorization": f"Bearer {service_role}",
            "apikey": service_role,
        })
        response.raise_for_status()

        suffix = Path(file_path).suffix or ""
        temp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        temp.write(response.content)
        temp.flush()
        temp.close()
        return Path(temp.name)


async def extract_resume_text(resume_path: str, signed_url: str | None = None, bucket: str | None = None) -> Tuple[str, list[str]]:
    temp_file: Path | None = None
    if signed_url:
        temp_file = await download_file_from_storage(signed_url, bucket)
    else:
        temp_file = await download_file_from_storage(resume_path, bucket)
    path = temp_file

    if not path.exists():
        raise FileNotFoundError(f"Arquivo de curr√≠culo n√£o encontrado: {resume_path}")

    extension = path.suffix.lower()
    warnings: list[str] = []

    try:
        if extension == ".pdf":
            content = await extract_text_from_pdf(path)
            if not content.strip():
                warnings.append("Nenhum texto extra√≠do do PDF; verifique se √© digitalizado.")
        elif extension == ".docx":
            content = await extract_text_from_docx(path)
        elif extension == ".txt":
            content = await extract_text_from_plain(path)
        elif extension in SUPPORTED_IMAGE_EXTENSIONS:
            content = await extract_text_with_ocr(path)
            warnings.append("OCR aplicado em imagem; qualidade pode variar.")
        elif extension == ".doc":
            warnings.append("Formato .doc n√£o suportado diretamente. Converta para .docx ou PDF.")
            content = ""
        else:
            warnings.append(f"Extens√£o {extension} n√£o suportada. Envie PDF, DOCX ou TXT.")
            content = ""
    except Exception as e:
        warnings.append(f"Falha ao extrair texto do curr√≠culo ({extension}): {e}")
        content = ""

    if temp_file:
        try:
            temp_file.unlink(missing_ok=True)
        except Exception:
            pass

    return content.strip(), warnings

# Simula√ß√£o de an√°lise de transcri√ß√£o
async def analyze_transcript(transcript_path: str) -> str:
    """Simula leitura de transcri√ß√£o JSON"""
    await asyncio.sleep(1)
    return f"Transcri√ß√£o {transcript_path}: Candidato mostrou conhecimento t√©cnico e habilidades interpessoais."

# An√°lise real com OpenAI
async def analyze_candidate_with_openai(
    text_content: str, 
    stage_description: str, 
    requirements: list[dict],
    config: AIConfig,
    prompt_template: str | None = None
) -> EvaluationResult:
    """
    An√°lise real do candidato usando OpenAI
    """
    # Verificar se a chave da API est√° configurada
    print(f"[IA] Verificando chave OpenAI: '{config.openai_api_key[:10] if config.openai_api_key else 'VAZIA'}...'")
    print(f"[IA] Chave vazia: {not config.openai_api_key}")
    print(f"[IA] Chave strip vazia: {config.openai_api_key.strip() == '' if config.openai_api_key else 'N/A'}")
    
    if not config.openai_api_key or config.openai_api_key.strip() == "":
        print("[IA] Chave OpenAI n√£o configurada, usando an√°lise simulada")
        return await analyze_candidate_simulated(text_content, stage_description, requirements)
    
    print("[IA] Chave OpenAI configurada, prosseguindo com an√°lise real")

    print(f"[IA] ========== DEBUG DADOS PARA OPENAI ==========")
    print(f"[IA] Preparando an√°lise com:")
    print(f"[IA]   - Texto: {len(text_content)} caracteres")
    print(f"[IA]   - Descri√ß√£o da etapa: {len(stage_description)} caracteres")
    print(f"[IA]   - Requisitos: {len(requirements)} itens")
    print(f"[IA]   - Modelo: {config.model}")
    print(f"[IA]   - Temperature: {config.temperature}")
    print(f"[IA]   - Max tokens: {config.max_tokens}")
    print(f"[IA] ========== CONTE√öDO DO TEXTO ==========")
    print(f"[IA] {text_content}")
    print(f"[IA] ========== DESCRI√á√ÉO DA ETAPA ==========")
    print(f"[IA] {stage_description}")
    print(f"[IA] ========== REQUISITOS ==========")
    print(f"[IA] {requirements}")
    
    try:
        async with httpx.AsyncClient() as client:
            # Preparar prompt para an√°lise
            requirements_text = "\n".join([
                f"- {req.get('label', '')}: {req.get('description', '')} (peso: {req.get('weight', 1.0)})"
                for req in requirements
            ])
            if not requirements_text.strip():
                requirements_text = "- Nenhum requisito espec√≠fico informado; utilize a descri√ß√£o da etapa como refer√™ncia principal."
            
            base_prompt = prompt_template or """
Analise o candidato para esta etapa do processo seletivo de forma objetiva e baseada EXCLUSIVAMENTE nas informa√ß√µes fornecidas.

DESCRI√á√ÉO DA ETAPA (contexto principal a ser considerado):
{{STAGE_DESCRIPTION}}

REQUISITOS OU EXPECTATIVAS PARA ESTA ETAPA:
{{REQUIREMENTS_LIST}}

INFORMA√á√ïES DO CANDIDATO (texto real do curr√≠culo e anexos):
{{CANDIDATE_INFO}}

INSTRU√á√ïES CR√çTICAS (obrigat√≥rias):
1. Utilize a descri√ß√£o da etapa como refer√™ncia central para julgar a ader√™ncia do candidato.
2. Compare cada item encontrado no curr√≠culo com a descri√ß√£o/requisitos e explique a rela√ß√£o.
3. N√£o invente informa√ß√µes: cite apenas o que estiver explicitamente no curr√≠culo.
4. Se faltar alguma informa√ß√£o relevante, registre explicitamente que ela n√£o aparece no curr√≠culo.
5. Caso o curr√≠culo esteja vazio ou ileg√≠vel, informe isso claramente e atribua nota 0.

CRIT√âRIO DE PONTUA√á√ÉO (0 a 10):
- 0 significa nenhuma ader√™ncia aos requisitos ou compet√™ncias da etapa.
- 10 significa ader√™ncia total aos requisitos e expectativas descritas.
- Distribua a nota proporcionalmente ao atendimento dos requisitos, considerando pesos quando informados.
- Justifique a nota citando evid√™ncias concretas do curr√≠culo relacionadas √† descri√ß√£o da etapa.

FORMATO DE RESPOSTA (JSON obrigat√≥rio):
{"score": number, "analysis": string, "strengths": string[], "weaknesses": string[], "matched_requirements": string[], "missing_requirements": string[]}

REGRAS ADICIONAIS:
- Liste em "matched_requirements" apenas itens comprovados pelo curr√≠culo e que se conectem √† descri√ß√£o.
- Liste em "missing_requirements" requisitos/compet√™ncias relevantes que n√£o foram comprovados.
- Seja espec√≠fico nas listas: use frases curtas que expliquem a evid√™ncia (ou aus√™ncia) encontrada.
- N√£o inclua campos extras ou coment√°rios fora do JSON solicitado.
"""

            prompt = (
                base_prompt
                .replace("{{STAGE_DESCRIPTION}}", stage_description)
                .replace("{{REQUIREMENTS_LIST}}", requirements_text)
                .replace("{{CANDIDATE_INFO}}", text_content)
            )

            print(f"[IA] ========== PROMPT FINAL PARA OPENAI ==========")
            print(f"[IA] Prompt preparado: {len(prompt)} caracteres")
            # Evitar imprimir o prompt completo em produ√ß√£o
            # print(f"[IA] {prompt}")
            print(f"[IA] ========== FIM DO PROMPT ==========")
            print(f"[IA] Fazendo requisi√ß√£o para OpenAI...")

            # Monta payload com JSON Schema √∫nico (sem oneOf)
            payload = {
                "model": config.model,
                "messages": [
                    {
                        "role": "system",
                        "content": "Voc√™ √© um especialista em RH que analisa candidatos de forma objetiva e justa. Sempre responda em formato JSON v√°lido."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": config.temperature,
                "max_tokens": config.max_tokens,
                "response_format": {
                    "type": "json_schema",
                    "json_schema": {
                        "name": "evaluation_schema",
                        "schema": {
                            "type": "object",
                            "additionalProperties": False,
                            "properties": {
                                "score": {"type": "number", "minimum": 0, "maximum": 10},
                                "analysis": {"type": "string"},
                                "strengths": {"type": "array", "items": {"type": "string"}},
                                "weaknesses": {"type": "array", "items": {"type": "string"}},
                                "matched_requirements": {"type": "array", "items": {"type": "string"}},
                                "missing_requirements": {"type": "array", "items": {"type": "string"}}
                            },
                            "required": [
                                "score",
                                "analysis",
                                "strengths",
                                "weaknesses",
                                "matched_requirements",
                                "missing_requirements"
                            ]
                        },
                        "strict": True
                    }
                }
            }

            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {config.openai_api_key}",
                    "Content-Type": "application/json"
                },
                json=payload,
                timeout=30.0
            )

            print(f"[IA] Resposta OpenAI recebida: {response.status_code}")

            # Fallback autom√°tico se o schema for rejeitado (400)
            if response.status_code == 400:
                try:
                    err = response.json()
                    err_msg = (err.get("error", {}) or {}).get("message", "")
                except Exception:
                    err_msg = ""
                if "response_format" in err_msg and ("Invalid schema" in err_msg or "not permitted" in err_msg):
                    print("[IA] Aviso: Schema JSON rejeitado. Requisitando novamente com response_format=json_object...")
                    payload["response_format"] = {"type": "json_object"}
                    response = await client.post(
                        "https://api.openai.com/v1/chat/completions",
                        headers={
                            "Authorization": f"Bearer {config.openai_api_key}",
                            "Content-Type": "application/json"
                        },
                        json=payload,
                        timeout=30.0
                    )
                    print(f"[IA] Resposta OpenAI (fallback json_object): {response.status_code}")

            if response.status_code != 200:
                print(f"[IA] Erro na API OpenAI: {response.status_code} - {response.text}")
                raise Exception(f"Erro na API OpenAI: {response.status_code} - {response.text}")

            data = response.json()
            content = data["choices"][0]["message"]["content"]
            print(f"[IA] ========== RESPOSTA DA OPENAI ==========")
            print(f"[IA] Conte√∫do da resposta: {len(content)} caracteres")
            # Evitar imprimir a resposta completa
            # print(f"[IA] {content}")
            print(f"[IA] ========== FIM DA RESPOSTA ==========")

            # Extrair JSON da resposta
            try:
                print(f"[IA] Tentando extrair JSON da resposta...")
                # Tentar encontrar JSON na resposta
                start = content.find('{')
                end = content.rfind('}') + 1
                print(f"[IA] Posi√ß√µes JSON: start={start}, end={end}")
                if start != -1 and end != 0:
                    json_str = content[start:end]
                    print(f"[IA] JSON extra√≠do: {len(json_str)} caracteres")
                    result = json.loads(json_str)
                    print(f"[IA] JSON parseado com sucesso!")
                else:
                    print(f"[IA] JSON n√£o encontrado na resposta")
                    raise ValueError("JSON n√£o encontrado na resposta")
            except (json.JSONDecodeError, ValueError) as e:
                print(f"[IA] Erro ao fazer parse do JSON: {e}")
                print(f"[IA] Usando an√°lise simulada como fallback")
                # Fallback para an√°lise simulada se JSON inv√°lido
                return await analyze_candidate_simulated(text_content, stage_description, requirements)

            # Fun√ß√£o para converter objetos em strings se necess√°rio
            def ensure_string_list(items):
                if not isinstance(items, list):
                    return []
                result_list = []
                for item in items:
                    if isinstance(item, str):
                        result_list.append(item)
                    elif isinstance(item, dict) and "requirement" in item:
                        result_list.append(item["requirement"])
                    elif isinstance(item, dict) and "description" in item:
                        result_list.append(item["description"])
                    else:
                        result_list.append(str(item))
                return result_list

            # Mapear diferentes formatos de resposta da IA
            score = 5.0
            analysis = "An√°lise n√£o dispon√≠vel"
            strengths = []
            weaknesses = []
            matched_requirements = []
            missing_requirements = []
            recommendations = []

            # Verificar estrutura do JSON retornado pela OpenAI
            print(f"[IA] ========== ESTRUTURA DO JSON RECEBIDO ==========")
            print(f"[IA] Chaves no resultado: {list(result.keys())}")
            # Evitar imprimir JSON completo
            # print(f"[IA] {json.dumps(result, indent=2, ensure_ascii=False)}")
            print(f"[IA] ========== FIM DA ESTRUTURA ==========")

            # Formato atual da OpenAI (campos na raiz)
            if "score" in result:
                score = float(result.get("score", 5.0))
                analysis = result.get("analysis", "An√°lise n√£o dispon√≠vel")
                strengths = ensure_string_list(result.get("strengths", []))
                weaknesses = ensure_string_list(result.get("weaknesses", []))
                matched_requirements = ensure_string_list(result.get("matched_requirements", []))
                missing_requirements = ensure_string_list(result.get("missing_requirements", []))
                recommendations = []  # Removido - n√£o ser√° usado
            # Formato antigo (com estrutura "avaliacao") - manter para compatibilidade
            elif "avaliacao" in result:
                avaliacao = result["avaliacao"]
                # Tentar diferentes nomes de campos para pontua√ß√£o
                score = float(avaliacao.get("pontuacao_final", avaliacao.get("pontuacao", 5.0)))
                # Tentar diferentes nomes de campos para an√°lise
                analysis = avaliacao.get("justificativa_pontuacao", avaliacao.get("justificativa", avaliacao.get("analise", avaliacao.get("resumo", "An√°lise n√£o dispon√≠vel"))))
                strengths = ensure_string_list(avaliacao.get("pontos_fortes", []))
                weaknesses = ensure_string_list(avaliacao.get("pontos_que_deixam_a_desejar", []))
                matched_requirements = ensure_string_list(avaliacao.get("requisitos_atendidos", []))
                missing_requirements = ensure_string_list(avaliacao.get("requisitos_nao_atendidos", []))
                recommendations = []  # Removido - n√£o ser√° usado

            # Clamp da pontua√ß√£o [0,10]
            try:
                if score is None or not isinstance(score, (int, float)):
                    score = 0.0
                score = max(0.0, min(10.0, float(score)))
            except Exception:
                score = 0.0

            evaluation_result = EvaluationResult(
                score=score,
                analysis=analysis,
                matched_requirements=matched_requirements,
                missing_requirements=missing_requirements,
                strengths=strengths,
                weaknesses=weaknesses,
                recommendations=recommendations
            )

            print(f"[IA] ========== RESULTADO FINAL DA AN√ÅLISE ==========")
            print(f"[IA] Score: {evaluation_result.score}")
            print(f"[IA] Analysis: {evaluation_result.analysis}")
            print(f"[IA] Strengths: {evaluation_result.strengths}")
            print(f"[IA] Weaknesses: {evaluation_result.weaknesses}")
            print(f"[IA] Matched requirements: {evaluation_result.matched_requirements}")
            print(f"[IA] Missing requirements: {evaluation_result.missing_requirements}")
            print(f"[IA] ========== FIM DO RESULTADO ==========")

            print(f"[IA] DEBUG - JSON parseado completo:")
            print(f"[IA] {json.dumps(result, indent=2, ensure_ascii=False)}")

            return evaluation_result

    except Exception as e:
        print(f"Erro na an√°lise com OpenAI: {e}")
        # Fallback para an√°lise simulada
        return await analyze_candidate_simulated(text_content, stage_description, requirements)

# An√°lise simulada (fallback) - MELHORADA PARA USAR DADOS REAIS
async def analyze_candidate_simulated(
    text_content: str,
    stage_description: str,
    requirements: list[dict]
) -> EvaluationResult:
    """
    An√°lise simulada do candidato baseada exclusivamente no conte√∫do real do curr√≠culo
    """
    await asyncio.sleep(2)  # Simula processamento

    # Se n√£o houver conte√∫do de curr√≠culo, retornar an√°lise vazia
    if not text_content or not text_content.strip():
        return EvaluationResult(
            score=0.0,
            analysis="N√£o foi poss√≠vel realizar a an√°lise: curr√≠culo vazio ou n√£o fornecido.",
            matched_requirements=[],
            missing_requirements=["Curr√≠culo n√£o fornecido"],
            strengths=[],
            weaknesses=["Aus√™ncia de informa√ß√µes do candidato"],
            recommendations=["Fornecer curr√≠culo para an√°lise"]
        )

    text_lower = text_content.lower()
    stage_lower = stage_description.lower()

    # Pontua√ß√£o base (0-10)
    base_score = 5.0

    # An√°lise de correspond√™ncia com descri√ß√£o da etapa
    stage_keywords = ["vendas", "comercial", "atendimento", "cliente", "negocia√ß√£o", "desenvolvimento", "programa√ß√£o", "an√°lise", "gest√£o", "lideran√ßa"]
    stage_matches = sum(1 for keyword in stage_keywords if keyword in text_lower)
    stage_bonus = min(stage_matches * 0.3, 1.5)

    # An√°lise de requisitos baseada no conte√∫do real
    matched_reqs = []
    missing_reqs = []
    strengths = []
    weaknesses = []
    req_bonus = 0.0

    # Extrair informa√ß√µes reais do curr√≠culo para an√°lise
    lines = [line.strip() for line in text_content.split('\n') if line.strip()]
    experiences = []
    education = []
    skills = []

    for line in lines:
        if any(keyword in line.lower() for keyword in ["experi√™ncia", "trabalhou", "atuou", "cargo", "empresa"]):
            experiences.append(line)
        elif any(keyword in line.lower() for keyword in ["forma√ß√£o", "gradua√ß√£o", "curso", "universidade", "faculdade"]):
            education.append(line)
        elif any(keyword in line.lower() for keyword in ["habilidade", "compet√™ncia", "conhecimento", "skill"]):
            skills.append(line)

    # An√°lise baseada em experi√™ncias reais encontradas
    if experiences:
        exp_text = ' '.join(experiences).lower()
        if any(word in exp_text for word in ["vendas", "comercial", "cliente", "atendimento"]):
            strengths.append("Possui experi√™ncia comprovada em √°rea comercial/vendas baseada no curr√≠culo")
            matched_reqs.append("Experi√™ncia em vendas/comercial identificada no curr√≠culo")
            req_bonus += 1.0
        if any(word in exp_text for word in ["desenvolvimento", "programa√ß√£o", "software", "sistema"]):
            strengths.append("Demonstra experi√™ncia em desenvolvimento de software")
            matched_reqs.append("Experi√™ncia em desenvolvimento identificada")
            req_bonus += 1.0
        if any(word in exp_text for word in ["gest√£o", "lideran√ßa", "equipe", "coordena√ß√£o"]):
            strengths.append("Apresenta experi√™ncia em gest√£o e lideran√ßa")
            matched_reqs.append("Experi√™ncia em gest√£o identificada")
            req_bonus += 0.8

    # An√°lise baseada em forma√ß√£o
    if education:
        edu_text = ' '.join(education).lower()
        if any(word in edu_text for word in ["administra√ß√£o", "engenharia", "computa√ß√£o", "sistemas"]):
            strengths.append("Forma√ß√£o acad√™mica relevante identificada no curr√≠culo")
            req_bonus += 0.5

    # An√°lise baseada em habilidades
    if skills:
        skills_text = ' '.join(skills).lower()
        if any(word in skills_text for word in ["comunica√ß√£o", "trabalho em equipe", "lideran√ßa"]):
            strengths.append("Habilidades interpessoais identificadas no curr√≠culo")
            req_bonus += 0.3

    # An√°lise espec√≠fica dos requisitos da etapa baseada no conte√∫do real
    for req in requirements:
        req_text = req.get("label", "").lower()
        req_desc = req.get("description", "").lower()
        req_weight = req.get("weight", 1.0)

        # Verificar se o requisito est√° presente no conte√∫do real do curr√≠culo
        if req_text in text_lower or req_desc in text_lower:
            matched_reqs.append(f"Requisito atendido: {req.get('label', '')} - {req.get('description', '')}")
            req_bonus += 0.5 * req_weight
        else:
            missing_reqs.append(f"Requisito n√£o atendido: {req.get('label', '')} - {req.get('description', '')}")

    # Se n√£o encontrou pontos fortes espec√≠ficos, criar baseados no conte√∫do geral
    if not strengths and text_content.strip():
        word_count = len(text_content.split())
        if word_count > 100:
            strengths.append("Curr√≠culo detalhado com informa√ß√µes abrangentes")
        elif word_count > 50:
            strengths.append("Curr√≠culo com informa√ß√µes relevantes")
        else:
            strengths.append("Curr√≠culo b√°sico fornecido")

    # An√°lise de pontos de melhoria baseados na aus√™ncia de informa√ß√µes
    if not any(word in text_lower for word in ["experi√™ncia", "trabalhou", "atuou"]):
        weaknesses.append("Aus√™ncia de informa√ß√µes sobre experi√™ncias profissionais")
        missing_reqs.append("Experi√™ncia profissional n√£o detalhada no curr√≠culo")

    if not any(word in text_lower for word in ["forma√ß√£o", "gradua√ß√£o", "curso"]):
        weaknesses.append("Aus√™ncia de informa√ß√µes sobre forma√ß√£o acad√™mica")
        missing_reqs.append("Forma√ß√£o acad√™mica n√£o informada")

    # C√°lculo da pontua√ß√£o final baseada no conte√∫do real
    content_score = min(len(strengths) * 1.5 + req_bonus, 5.0)
    final_score = min(base_score + stage_bonus + content_score, 10.0)

    # Gera an√°lise textual baseada exclusivamente no conte√∫do real
    analysis = f"""
    An√°lise baseada exclusivamente no conte√∫do do curr√≠culo fornecido:

    ‚úÖ Informa√ß√µes encontradas no curr√≠culo:
    - {len(experiences)} men√ß√µes √† experi√™ncia profissional
    - {len(education)} men√ß√µes √† forma√ß√£o acad√™mica
    - {len(skills)} men√ß√µes √† habilidades/compet√™ncias
    - {len(matched_reqs)} requisitos da etapa atendidos
    - {stage_matches} palavras-chave da descri√ß√£o da etapa encontradas

    ‚ö†Ô∏è Lacunas identificadas:
    - {len(missing_reqs)} requisitos da etapa n√£o atendidos
    - Principais pontos de melhoria baseados no conte√∫do fornecido

    üìä Pontua√ß√£o: {final_score:.1f}/10 (baseada na quantidade e qualidade das informa√ß√µes do curr√≠culo)
    """

    # Adiciona pontos de melhoria espec√≠ficos se n√£o houver requisitos espec√≠ficos
    if not weaknesses:
        if len(text_content) < 200:
            weaknesses.append("Curr√≠culo muito conciso - considere adicionar mais detalhes sobre experi√™ncias")
        else:
            weaknesses.append("Curr√≠culo analisado com sucesso - nenhuma fraqueza cr√≠tica identificada")

    return EvaluationResult(
        score=round(final_score, 1),
        analysis=analysis.strip(),
        matched_requirements=matched_reqs,
        missing_requirements=missing_reqs,
        strengths=strengths,
        weaknesses=weaknesses,
        recommendations=["Revisar curr√≠culo para pr√≥xima an√°lise", "Considerar entrevista t√©cnica"]
    )

# Buscar configura√ß√µes do usu√°rio - MELHORADA COM VALIDA√á√ïES
async def get_user_ai_config(user_id: str) -> AIConfig:
    """
    Busca configura√ß√µes da IA do usu√°rio com valida√ß√µes robustas.
    Se n√£o houver configura√ß√£o persistida, utiliza vari√°veis de ambiente como fallback.
    """
    print(f"[IA] ========== INICIANDO BUSCA DE CONFIGURA√á√ïES ==========")
    print(f"[IA] User ID: {user_id}")

    # Vari√°veis de ambiente como fallback
    env_api_key = os.getenv("OPENAI_API_KEY", "")
    env_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    env_temperature = float(os.getenv("OPENAI_TEMPERATURE", "0.3"))
    env_max_tokens = int(os.getenv("OPENAI_MAX_TOKENS", "2000"))
    require_user_key = os.getenv("AI_REQUIRE_USER_KEY", "false").lower() in ("1", "true", "yes", "y")

    supabase_url = os.getenv("SUPABASE_URL")
    service_role = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

    print(f"[IA] ========== VARI√ÅVEIS DE AMBIENTE ==========")
    print(f"[IA] SUPABASE_URL: {supabase_url}")
    print(f"[IA] SUPABASE_SERVICE_ROLE_KEY: {'CONFIGURADO' if service_role else 'VAZIO'}")
    print(f"[IA] OPENAI_API_KEY ambiente: {env_api_key[:6] + '...' if env_api_key else 'VAZIO'}")
    print(f"[IA] AI_REQUIRE_USER_KEY: {'ON' if require_user_key else 'OFF'}")

    config_source = "none"  # user | env | none

    # Tentar buscar configura√ß√µes do banco de dados
    if supabase_url and service_role and user_id and user_id != "default":
        print(f"[IA] ========== BUSCANDO CONFIGURA√á√ïES NO BANCO ==========")
        print(f"[IA] Fazendo requisi√ß√£o para: {supabase_url}/rest/v1/rpc/get_ai_settings_by_user")

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{supabase_url}/rest/v1/rpc/get_ai_settings_by_user",
                    json={"p_user_id": user_id},
                    headers={
                        "apikey": service_role,
                        "Authorization": f"Bearer {service_role}",
                        "Accept": "application/json",
                        "Content-Type": "application/json",
                    },
                    timeout=15.0,
                )

                print(f"[IA] Status da resposta do banco: {response.status_code}")

                if response.status_code == 200:
                    data = response.json()
                    print(f"[IA] Dados retornados do banco: {len(data) if data else 0} registros")

                    if data and len(data) > 0:
                        record = data[0]
                        print(f"[IA] ========== DADOS DO USU√ÅRIO ENCONTRADOS ==========")
                        print(f"[IA] Model: {record.get('model', 'N√ÉO CONFIGURADO')}")
                        print(f"[IA] Temperature: {record.get('temperature', 'N√ÉO CONFIGURADO')}")
                        print(f"[IA] Max Tokens: {record.get('max_tokens', 'N√ÉO CONFIGURADO')}")

                        # Processar chave da API
                        api_key_raw = record.get("openai_api_key")
                        print(f"[IA] Chave API raw encontrada: {'SIM' if api_key_raw else 'N√ÉO'}")

                        if api_key_raw:
                            try:
                                decoded_key = base64.b64decode(api_key_raw).decode('utf-8')
                                print(f"[IA] Chave API decodificada com sucesso: {decoded_key[:6]}...")

                                # Validar se a chave parece v√°lida (n√£o √© vazia ap√≥s decodificar)
                                if decoded_key and decoded_key.strip():
                                    env_api_key = decoded_key.strip()
                                    print(f"[IA] ‚úÖ Chave API v√°lida atribu√≠da do banco de dados")
                                    config_source = "user"
                                else:
                                    print(f"[IA] ‚ùå Chave API decodificada est√° vazia")

                            except Exception as decode_error:
                                print(f"[IA] ‚ùå Erro ao decodificar chave API: {decode_error}")
                                print(f"[IA] Chave raw: {api_key_raw[:50] if api_key_raw else 'VAZIA'}...")
                        else:
                            print(f"[IA] ‚ùå Chave API n√£o encontrada no registro do usu√°rio")

                        # Aplicar outras configura√ß√µes se dispon√≠veis
                        if record.get("model"):
                            env_model = record.get("model")
                            print(f"[IA] Modelo atualizado: {env_model}")

                        if record.get("temperature") is not None:
                            env_temperature = float(record.get("temperature"))
                            print(f"[IA] Temperature atualizada: {env_temperature}")

                        if record.get("max_tokens"):
                            env_max_tokens = int(record.get("max_tokens"))
                            print(f"[IA] Max tokens atualizado: {env_max_tokens}")

                    else:
                        print(f"[IA] ‚ùå Nenhum registro encontrado para o usu√°rio {user_id}")
                        print(f"[IA] ‚ö†Ô∏è Usando configura√ß√µes de ambiente como fallback")

                elif response.status_code == 404:
                    print(f"[IA] ‚ùå Fun√ß√£o get_ai_settings_by_user n√£o encontrada - verifique se existe no banco")
                else:
                    print(f"[IA] ‚ùå Erro na resposta do banco: {response.status_code}")
                    print(f"[IA] Resposta: {response.text}")

        except Exception as db_error:
            print(f"[IA] ‚ùå Falha cr√≠tica ao conectar com banco de dados: {db_error}")
            print(f"[IA] ‚ö†Ô∏è Continuando com configura√ß√µes de ambiente")

    else:
        print(f"[IA] ========== PULANDO BUSCA NO BANCO ==========")
        if not supabase_url:
            print(f"[IA] ‚ùå SUPABASE_URL n√£o configurada")
        if not service_role:
            print(f"[IA] ‚ùå SUPABASE_SERVICE_ROLE_KEY n√£o configurada")
        if not user_id or user_id == "default":
            print(f"[IA] ‚ùå User ID inv√°lido: {user_id}")

    # Aplicar pol√≠tica: exigir chave do usu√°rio quando flag est√° ON
    if require_user_key and config_source != "user":
        # Desativar uso de OPENAI_API_KEY de ambiente
        env_api_key = ""
        print("[IA] üîí AI_REQUIRE_USER_KEY=ON ‚Üí desativando fallback de OPENAI_API_KEY de ambiente")
        config_source = "none"

    # Valida√ß√£o final da configura√ß√£o
    print(f"[IA] ========== CONFIGURA√á√ÉO FINAL ==========")
    print(f"[IA] Modelo: {env_model}")
    print(f"[IA] Temperature: {env_temperature}")
    print(f"[IA] Max Tokens: {env_max_tokens}")
    print(f"[IA] Chave API configurada: {'‚úÖ SIM' if env_api_key and env_api_key.strip() else '‚ùå N√ÉO'} (source={config_source})")

    if env_api_key and env_api_key.strip():
        print(f"[IA] Chave API (prefixo): {env_api_key[:6]}...")
    else:
        print(f"[IA] ‚ùå ATEN√á√ÉO: Chave API n√£o configurada - an√°lise ser√° simulada")

    return AIConfig(
        openai_api_key=env_api_key.strip() if env_api_key else "",
        model=env_model,
        temperature=env_temperature,
        max_tokens=env_max_tokens,
    )

@app.post("/v1/transcribe", response_model=RunStatus)
async def transcribe(request: TranscribeRequest):
    run_id = str(uuid.uuid4())
    runs[run_id] = {
        "id": run_id,
        "type": "transcribe",
        "status": "running",
        "progress": 0,
        "result": None,
        "created_at": datetime.now().isoformat()
    }
    
    asyncio.create_task(process_transcription(run_id, request.audio_path))
    
    return RunStatus(id=run_id, type="transcribe", status="running", progress=0)

async def process_transcription(run_id: str, audio_path: str):
    try:
        runs[run_id]["progress"] = 50
        transcript = await process_audio(audio_path)
        runs[run_id]["status"] = "succeeded"
        runs[run_id]["progress"] = 100
        runs[run_id]["result"] = {"transcript": transcript}
        runs[run_id]["finished_at"] = datetime.now().isoformat()
    except Exception as e:
        runs[run_id]["status"] = "failed"
        runs[run_id]["error"] = str(e)
        runs[run_id]["finished_at"] = datetime.now().isoformat()

@app.post("/v1/evaluate", response_model=RunStatus)
async def evaluate(request: EvaluateRequest):
    run_id = str(uuid.uuid4())
    print(f"[IA] Criando run de avalia√ß√£o: {run_id}")
    
    runs[run_id] = {
        "id": run_id,
        "type": "evaluate",
        "status": "running",
        "progress": 0,
        "result": None,
        "created_at": datetime.now().isoformat()
    }
    
    print(f"[IA] Run criado com sucesso. Total de runs: {len(runs)}")
    print(f"[IA] Runs dispon√≠veis: {list(runs.keys())}")
    
    asyncio.create_task(process_evaluation(run_id, request))
    
    return RunStatus(id=run_id, type="evaluate", status="running", progress=0)

async def process_evaluation(run_id: str, request: EvaluateRequest):
    try:
        runs[run_id]["progress"] = 20

        # Coleta conte√∫do de texto
        text_content = ""
        extraction_warnings: list[str] = []

        print("[IA] Recebido curr√≠culo:", request.resume_path, request.resume_bucket, request.resume_signed_url)

        if request.resume_path:
            runs[run_id]["progress"] = 40
            resume_text = ""
            resume_warnings: list[str] = []
            try:
                print(f"[IA] ========== DEBUG EXTRA√á√ÉO DE CURR√çCULO ==========")
                print(f"[IA] Tentando extrair curr√≠culo:")
                print(f"[IA]   - resume_path: {request.resume_path}")
                print(f"[IA]   - resume_signed_url: {request.resume_signed_url}")
                print(f"[IA]   - resume_bucket: {request.resume_bucket}")

                resume_text, resume_warnings = await extract_resume_text(
                    request.resume_path,
                    request.resume_signed_url,
                    request.resume_bucket,
                )
                print(f"[IA] ========== RESULTADO DA EXTRA√á√ÉO ==========")
                print(f"[IA] Texto extra√≠do do curr√≠culo ({len(resume_text)} chars):")
                print(f"[IA] ========== CONTE√öDO COMPLETO ==========")
                print(f"[IA] {resume_text}")
                print(f"[IA] ========== FIM DO CONTE√öDO ==========")
                print(f"[IA] Warnings da extra√ß√£o: {resume_warnings}")
            except Exception as ex:
                resume_warnings.append(f"Falha ao ler curr√≠culo: {ex}")
                print(f"[IA] Erro ao extrair curr√≠culo: {ex}")

            if resume_text:
                text_content += resume_text + "\n\n"
                print(f"[IA] Curr√≠culo adicionado ao conte√∫do total")
                print(f"[IA] Texto do curr√≠culo extra√≠do: {resume_text[:200]}...")
            else:
                print("[IA] AVISO: Nenhum texto extra√≠do do curr√≠culo")
            extraction_warnings.extend(resume_warnings)
        
        if request.audio_path:
            runs[run_id]["progress"] = 60
            text_content += await process_audio(request.audio_path) + "\n\n"

        if request.transcript_path:
            runs[run_id]["progress"] = 80
            text_content += await analyze_transcript(request.transcript_path) + "\n\n"
        
        # Buscar configura√ß√µes da IA do usu√°rio
        print(f"[IA] User ID recebido: {request.user_id}")
        print(f"[IA] Tipo do user_id: {type(request.user_id)}")
        print(f"[IA] User ID ser√° usado: {request.user_id or 'default'}")
        config = await get_user_ai_config(request.user_id or "default")

        # Define descri√ß√£o da etapa e requisitos com base no payload fornecido
        stage_payload = request.stage
        stage_description = "Etapa do processo seletivo"

        if stage_payload and stage_payload.name:
            stage_description = stage_payload.name

        # Priorizar a descri√ß√£o detalhada da etapa
        if stage_payload and stage_payload.description:
            stage_description = stage_payload.description
        elif stage_payload and stage_payload.job_description:
            stage_description += f"\nDescri√ß√£o da vaga: {stage_payload.job_description}"
        
        # Usar a descri√ß√£o detalhada da etapa como base para an√°lise
        # Se n√£o houver requisitos espec√≠ficos, usar a descri√ß√£o da etapa
        requirements_payload = []
        
        if request.requirements and len(request.requirements) > 0:
            # Se h√° requisitos espec√≠ficos, usar eles
            requirements_payload = [
                {
                    "label": req.label or "",
                    "description": req.description or "",
                    "weight": req.weight or 1.0,
                }
                for req in request.requirements
            ]
        else:
            # Se n√£o h√° requisitos espec√≠ficos, criar um requisito baseado na descri√ß√£o da etapa
            requirements_payload = [
                {
                    "label": "Requisitos da Etapa",
                    "description": stage_description,
                    "weight": 1.0,
                }
            ]
        
        print(f"[IA] Descri√ß√£o da etapa: {stage_description}")
        print(f"[IA] Requisitos para an√°lise ({len(requirements_payload)}): {requirements_payload}")
        print(f"[IA] ========== DEBUG CONTE√öDO PARA AN√ÅLISE ==========")
        print(f"[IA] Conte√∫do total para an√°lise ({len(text_content)} chars):")
        print(f"[IA] ========== CONTE√öDO COMPLETO ==========")
        print(f"[IA] {text_content}")
        print(f"[IA] ========== FIM DO CONTE√öDO ==========")
        print(f"[IA] ========== DEBUG PROMPT TEMPLATE ==========")
        print(f"[IA] Prompt template recebido: {request.prompt_template[:200] if request.prompt_template else 'NENHUM'}...")
        if request.prompt_template:
            print(f"[IA] ========== PROMPT TEMPLATE COMPLETO ==========")
            print(f"[IA] {request.prompt_template}")
            print(f"[IA] ========== FIM DO PROMPT TEMPLATE ==========")

        # An√°lise da IA
        runs[run_id]["progress"] = 90
        print(f"[IA] Chamando analyze_candidate_with_openai com config: {config}")
        print(f"[IA] Config OpenAI key: {config.openai_api_key[:10] if config.openai_api_key else 'VAZIA'}...")
        evaluation = await analyze_candidate_with_openai(
            text_content,
            stage_description,
            requirements_payload,
            config,
            prompt_template=request.prompt_template,
        )
        print(f"[IA] Resultado da an√°lise: score={evaluation.score}, strengths={len(evaluation.strengths)}, weaknesses={len(evaluation.weaknesses)}")
        
        runs[run_id]["status"] = "succeeded"
        runs[run_id]["progress"] = 100
        
        # Preparar resultado da an√°lise
        analysis_result = {
            "score": evaluation.score,
            "analysis": evaluation.analysis,
            "matched_requirements": evaluation.matched_requirements,
            "missing_requirements": evaluation.missing_requirements,
            "strengths": evaluation.strengths,
            "weaknesses": evaluation.weaknesses,
            "recommendations": evaluation.recommendations,
            "extraction_warnings": extraction_warnings,
            "stage_id": request.stage_id,
            "application_id": request.application_id,
            "prompt_template": request.prompt_template,
            "stage": request.stage.model_dump() if request.stage else None,
            "requirements": [req.model_dump() for req in (request.requirements or [])],
        }
        
        runs[run_id]["result"] = analysis_result
        runs[run_id]["finished_at"] = datetime.now().isoformat()
        
        # Salvar resultado no banco de dados
        await save_analysis_to_database(run_id, analysis_result)
        
    except Exception as e:
        runs[run_id]["status"] = "failed"
        runs[run_id]["error"] = str(e)
        runs[run_id]["finished_at"] = datetime.now().isoformat()

@app.get("/health")
async def health_check():
    return {"status": "ok", "runs_count": len(runs), "timestamp": datetime.now().isoformat()}

@app.get("/v1/runs/{run_id}", response_model=RunStatus)
async def get_run(run_id: str):
    print(f"[IA] GET /v1/runs/{run_id}")
    print(f"[IA] Runs dispon√≠veis: {list(runs.keys())}")
    
    if run_id not in runs:
        print(f"[IA] Run {run_id} n√£o encontrado")
        raise HTTPException(status_code=404, detail="Run not found")
    
    run_data = runs[run_id]
    print(f"[IA] Run encontrado: {run_data}")
    return RunStatus(
        id=run_data["id"],
        type=run_data["type"],
        status=run_data["status"],
        progress=run_data["progress"],
        error=run_data.get("error"),
        result=run_data.get("result")
    )

# Fun√ß√£o para salvar an√°lise no banco de dados
async def save_analysis_to_database(run_id: str, analysis_result: dict):
    """
    Salva o resultado da an√°lise no banco de dados
    """
    try:
        service_role = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        base_url = (
            os.getenv("SUPABASE_URL")
            or os.getenv("NEXT_PUBLIC_SUPABASE_URL")
            or (os.getenv("SUPABASE_STORAGE_URL") or "").replace("/storage/v1", "")
        )

        if not base_url or not service_role:
            print(f"[IA] Aviso: N√£o foi poss√≠vel salvar an√°lise {run_id} - vari√°veis de ambiente n√£o configuradas")
            return
        
        async with httpx.AsyncClient() as client:
            # Atualizar o registro na tabela stage_ai_runs usando WHERE clause
            response = await client.patch(
                f"{base_url}/rest/v1/stage_ai_runs?run_id=eq.{run_id}",
                json={
                    "result": analysis_result,
                    "status": "succeeded",
                    "finished_at": datetime.now().isoformat()
                },
                headers={
                    "apikey": service_role,
                    "Authorization": f"Bearer {service_role}",
                    "Accept": "application/json",
                    "Content-Type": "application/json",
                    "Prefer": "return=minimal"
                },
                timeout=10.0,
            )
            
            if response.status_code in [200, 204]:
                print(f"[IA] An√°lise {run_id} salva no banco com sucesso")
            else:
                print(f"[IA] Erro ao salvar an√°lise {run_id}: {response.status_code} - {response.text}")
                
    except Exception as e:
        print(f"[IA] Erro ao salvar an√°lise {run_id} no banco: {e}")

@app.get("/health")
async def health():
    return {
        "status": "healthy", 
        "runs_active": len([r for r in runs.values() if r["status"] == "running"]),
        "version": "0.2.0"
    }

# Endpoint para testar configura√ß√£o da IA
@app.post("/v1/test-config")
async def test_config(config: AIConfig):
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {config.openai_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": config.model,
                    "messages": [
                        {
                            "role": "user",
                            "content": "Teste de conex√£o. Responda apenas 'OK' se recebeu esta mensagem."
                        }
                    ],
                    "max_tokens": 10,
                    "temperature": 0
                },
                timeout=10.0
            )
            
            if response.status_code == 200:
                return {"success": True, "message": "Configura√ß√£o v√°lida"}
            else:
                return {"success": False, "message": f"Erro: {response.status_code}"}
                
    except Exception as e:
        return {"success": False, "message": f"Erro: {str(e)}"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
